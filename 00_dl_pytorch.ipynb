{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a13b1a0-6a83-4cf7-b3df-b431e72b0728",
   "metadata": {},
   "source": [
    "## 00. Introduction to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "661bb330-9ef0-4e51-92a3-812cad8117d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:  2.4.0\n",
      "CUDA available:  True\n",
      "CUDA device count:  1\n",
      "CUDA device name:  NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "print(\"PyTorch version: \", torch.__version__)\n",
    "print(\"CUDA available: \", torch.cuda.is_available())\n",
    "print(\"CUDA device count: \", torch.cuda.device_count())\n",
    "print(\"CUDA device name: \", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6dcd7937-0a5e-4a7f-91c2-fe5814aae584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor_information(ts: torch.tensor):\n",
    "    print(f'tensor size: {ts.shape}')\n",
    "    print(f'tensor device: {ts.device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d6f0016e-d777-46da-8a2f-16f3581b480d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0019, 0.1452, 0.1418],\n",
       "         [0.7174, 0.2271, 0.4234],\n",
       "         [0.6071, 0.0164, 0.2259],\n",
       "         ...,\n",
       "         [0.5483, 0.6252, 0.9635],\n",
       "         [0.1427, 0.4120, 0.7976],\n",
       "         [0.9527, 0.4132, 0.4388]],\n",
       "\n",
       "        [[0.4394, 0.8605, 0.1479],\n",
       "         [0.8384, 0.0377, 0.2770],\n",
       "         [0.3225, 0.1445, 0.5952],\n",
       "         ...,\n",
       "         [0.7870, 0.3978, 0.5021],\n",
       "         [0.1261, 0.2794, 0.0816],\n",
       "         [0.5699, 0.1649, 0.9923]],\n",
       "\n",
       "        [[0.7058, 0.4820, 0.5028],\n",
       "         [0.2016, 0.1640, 0.2711],\n",
       "         [0.1370, 0.7307, 0.4489],\n",
       "         ...,\n",
       "         [0.4662, 0.2431, 0.6964],\n",
       "         [0.0732, 0.4878, 0.6695],\n",
       "         [0.9666, 0.3011, 0.8204]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5293, 0.3726, 0.8699],\n",
       "         [0.6569, 0.8821, 0.8414],\n",
       "         [0.7678, 0.3018, 0.7636],\n",
       "         ...,\n",
       "         [0.8237, 0.1217, 0.9501],\n",
       "         [0.1818, 0.5244, 0.5091],\n",
       "         [0.8704, 0.3233, 0.4728]],\n",
       "\n",
       "        [[0.9673, 0.1640, 0.8905],\n",
       "         [0.1090, 0.9218, 0.6931],\n",
       "         [0.3749, 0.1536, 0.2956],\n",
       "         ...,\n",
       "         [0.0643, 0.3796, 0.9754],\n",
       "         [0.5832, 0.8469, 0.6386],\n",
       "         [0.8116, 0.8460, 0.3375]],\n",
       "\n",
       "        [[0.0689, 0.0548, 0.6815],\n",
       "         [0.9825, 0.1174, 0.9104],\n",
       "         [0.1584, 0.2870, 0.8804],\n",
       "         ...,\n",
       "         [0.6981, 0.4763, 0.8854],\n",
       "         [0.0049, 0.1796, 0.8599],\n",
       "         [0.6754, 0.3421, 0.6955]]], device='cuda:0')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(size=(244, 244, 3), dtype=torch.float32, device='cuda')\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b69baa33-c5ed-4e02-bbad-f592d967f7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size: torch.Size([244, 244, 3])\n",
      "tensor device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "get_tensor_information(ts=tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8b88a743-a094-4c26-9885-5be58f19c128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor(dtype=torch.int32, data=[1,2,3])\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bc287f9b-97d0-43ed-be74-a610ab55a948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ae041d71-3696-418f-9afb-dbc38b4a0fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6fabfe14-ba88-41fb-b7e6-15610e4c1033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8812, 0.3384, 0.4496, 0.3020, 0.5025],\n",
       "        [0.9117, 0.4681, 0.8962, 0.6064, 0.8594],\n",
       "        [0.7740, 0.4031, 0.7093, 0.0453, 0.0705],\n",
       "        [0.8727, 0.6723, 0.4420, 0.0068, 0.6796],\n",
       "        [0.0143, 0.6429, 0.4169, 0.5914, 0.4648]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(size=(5,5))\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "649ad27d-3e63-48c7-a04d-e9230a99d0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7039, 1.1641, 1.3614, 0.7911, 1.2043],\n",
       "        [2.4655, 1.8492, 2.0914, 1.1123, 1.7353],\n",
       "        [1.6392, 0.8124, 1.2618, 0.5524, 0.8490],\n",
       "        [1.7398, 1.2298, 1.5947, 1.0933, 1.3681],\n",
       "        [1.4443, 1.1703, 1.3335, 0.6920, 1.2072]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(random_tensor, random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0f42c145-edc7-47ca-ba42-26ff1c3ba157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7039, 1.1641, 1.3614, 0.7911, 1.2043],\n",
       "        [2.4655, 1.8492, 2.0914, 1.1123, 1.7353],\n",
       "        [1.6392, 0.8124, 1.2618, 0.5524, 0.8490],\n",
       "        [1.7398, 1.2298, 1.5947, 1.0933, 1.3681],\n",
       "        [1.4443, 1.1703, 1.3335, 0.6920, 1.2072]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(random_tensor, random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cb147f78-997c-4e0c-8d05-d741104c3897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tensor = torch.tensor(data=[1,2,3])\n",
    "a_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7cd84a00-3ae8-4a90-947a-7e3703c78e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927814c8-e632-4abb-82eb-3a6007dcae3c",
   "metadata": {},
   "source": [
    "### Manipulating Tensors\n",
    "\n",
    "Tensor operations include: \n",
    "- addition\n",
    "- substraction\n",
    "- multiplication (element-wise)\n",
    "- division\n",
    "- matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8eeade91-4cb9-4e23-97e5-50cdc9f35e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a tensor\n",
    "ts = torch.tensor([1, 2, 3])\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d45e2ee9-8541-4e22-a83a-b1baad94f874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = ts * 10\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "15676dd8-b23e-4713-b2b7-065ca263fc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100, 200, 300])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pytorch in-built functions\n",
    "torch.mul(ts, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b534d81-847b-468a-8def-f73b4987ff35",
   "metadata": {},
   "source": [
    "### Matrix multiplication\n",
    "\n",
    "There are two main ways to perform matrix multiplication:\n",
    "1. element-wise\n",
    "2. dot-product\n",
    "\n",
    "There are two main rules that peforming matrix multiplication needs to satisfy: \n",
    "1. the **inner dimensions** must match:\n",
    "   - `(3, 2) @ (3, 2)` won't work\n",
    "   - `(3, 2) @ (2, 3)` will work\n",
    "2. the resulting matrix has the shape of the **outer dimension**:\n",
    "   - `(2, 3) @ (3, 2)` -> `(2,2)`\n",
    "  \n",
    "playground - http://matrixmultiplication.xyz/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "33f6e0f3-4eb6-437f-827a-154761dc41fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4118, 1.1953, 0.3980],\n",
       "        [0.2074, 0.6621, 0.2131],\n",
       "        [0.3308, 1.0351, 0.3355]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.rand(3, 2), torch.rand(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5177d4dc-6dd7-4441-9b8c-0e5a24359363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(a_tensor, a_tensor)\n",
    "## For 2D tensors (matrices): torch.matmul(A, B) performs matrix multiplication.\n",
    "## For 1D tensors (vectors): torch.matmul(a, b) performs the dot product if one of the tensors is 1D and the other is 2D or if both are 1D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc90c55a-0951-44e8-bb84-082090171806",
   "metadata": {},
   "source": [
    "### one of the most common errors in deep learning: shape errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7b320a92-2310-4578-a8a8-e93e407fb837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapes for matrix multiplication\n",
    "tensor_a = torch.tensor([[1,2],\n",
    "                         [3,2],\n",
    "                         [4,3]])\n",
    "tensor_b = torch.tensor([[2,3],\n",
    "                         [4,3],\n",
    "                         [6,7]])\n",
    "## these tensors cannot be multiplied because the inner dimensions aren't the same\n",
    "## we need to perform matrix transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "45cf7ecc-6126-4130-85ea-ecf9a8d8ccca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a.shape, tensor_b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0538f136-0a45-4bf0-88a1-a857a20cf3f6",
   "metadata": {},
   "source": [
    "To fix tensor shape issues, we can manipulate the shape of one of our tensors using a **transpose**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7b09706c-5c0e-4e41-a58b-2019b9f39aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size of matrix a = torch.Size([3, 2]) and matrix b = torch.Size([3, 2])\n",
      "They cannot be multiplied since their inner dimensions don't match\n",
      "\n",
      "We can perform a matrix manipulation to one of the matrices\n",
      "Transposed matrix b: tensor([[2, 4, 6],\n",
      "        [3, 3, 7]])\n",
      "matrix b.T still contains the same information as the original matrix b\n",
      "\n",
      "Now these matrices have the same inner dimension a = torch.Size([3, 2]); b = torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original size of matrix a = {tensor_a.shape} and matrix b = {tensor_b.shape}\")\n",
    "print(f\"They cannot be multiplied since their inner dimensions don't match\")\n",
    "print(f\"\\nWe can perform a matrix manipulation to one of the matrices\")\n",
    "print(f\"Transposed matrix b: {tensor_b.T}\")\n",
    "print(\"matrix b.T still contains the same information as the original matrix b\")\n",
    "print(f\"\\nNow these matrices have the same inner dimension a = {tensor_a.shape}; b = {tensor_b.T.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ac7e8283-4dd0-45fc-9e63-40361ddf5c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8, 10, 20],\n",
       "        [12, 18, 32],\n",
       "        [17, 25, 45]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiplied_matrices = torch.matmul(tensor_a, tensor_b.T)\n",
    "multiplied_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6847dee-d053-4612-a169-765added73d2",
   "metadata": {},
   "source": [
    "### 3D tensors multiplication\n",
    "For tensors A with shape (B, M, N) and B with shape (B, N, P), where B is the batch size:\n",
    "The last dimension of A (size N) must match the second-to-last dimension of B (also size N).\n",
    "The resulting tensor will have shape (B, M, P)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e2987027-17b3-4ed2-9d80-90db89907638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3239, 0.2150, 0.6766, 0.1798, 0.4749, 0.1063, 0.4723],\n",
       "         [0.5791, 0.4355, 0.6833, 0.5643, 0.0695, 0.0421, 0.4657]],\n",
       "\n",
       "        [[0.5563, 0.2574, 0.1049, 0.4976, 0.5109, 0.2089, 0.1141],\n",
       "         [0.5614, 0.4603, 0.5957, 0.7471, 0.8157, 0.6939, 0.8273]],\n",
       "\n",
       "        [[0.3526, 0.3491, 0.8292, 0.7364, 0.8466, 0.0594, 0.6825],\n",
       "         [0.7234, 0.9051, 0.9751, 0.7533, 0.6006, 0.3450, 0.6708]],\n",
       "\n",
       "        [[0.6808, 0.7684, 0.9164, 0.3660, 0.0253, 0.8175, 0.7419],\n",
       "         [0.2284, 0.8319, 0.0400, 0.6402, 0.8662, 0.1340, 0.6311]],\n",
       "\n",
       "        [[0.0858, 0.3308, 0.3261, 0.0799, 0.3893, 0.0271, 0.7781],\n",
       "         [0.2100, 0.8567, 0.4808, 0.3027, 0.4635, 0.0083, 0.7360]]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_dimension_ts1 = torch.rand(size=(5, 2, 7))\n",
    "three_dimension_ts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cc9ecdcb-8d8d-4353-8158-f9b618bd0475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0409],\n",
       "         [0.3363],\n",
       "         [0.1689],\n",
       "         [0.6693],\n",
       "         [0.6914],\n",
       "         [0.9079],\n",
       "         [0.6431]],\n",
       "\n",
       "        [[0.2853],\n",
       "         [0.9485],\n",
       "         [0.0837],\n",
       "         [0.0110],\n",
       "         [0.9562],\n",
       "         [0.5654],\n",
       "         [0.7546]],\n",
       "\n",
       "        [[0.1631],\n",
       "         [0.2783],\n",
       "         [0.9989],\n",
       "         [0.9824],\n",
       "         [0.4226],\n",
       "         [0.7310],\n",
       "         [0.7705]],\n",
       "\n",
       "        [[0.2911],\n",
       "         [0.1315],\n",
       "         [0.4335],\n",
       "         [0.9765],\n",
       "         [0.4031],\n",
       "         [0.6484],\n",
       "         [0.0657]],\n",
       "\n",
       "        [[0.4050],\n",
       "         [0.9004],\n",
       "         [0.8656],\n",
       "         [0.0184],\n",
       "         [0.7969],\n",
       "         [0.2735],\n",
       "         [0.0985]]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_dimension_ts2 = torch.rand(size=(5,7,1))\n",
    "three_dimension_ts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b494ac4c-c9bd-4fc7-b0db-5a09da2a2c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0489],\n",
       "         [1.0490]],\n",
       "\n",
       "        [[1.1098],\n",
       "         [2.4514]],\n",
       "\n",
       "        [[2.6334],\n",
       "         [3.1069]],\n",
       "\n",
       "        [[1.6428],\n",
       "         [1.2959]],\n",
       "\n",
       "        [[1.0108],\n",
       "         [1.7223]]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(three_dimension_ts1, three_dimension_ts2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f17d37-b20a-4cc7-87af-646bcb397ab8",
   "metadata": {},
   "source": [
    "### Tensors Aggregation\n",
    "Finding the min, max, mean, sum, etc (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5d78cea7-25c7-4704-8543-197a4c89f630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a 1d tensor \n",
    "x = torch.arange(start=0, end=100, step=10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "39d278c3-a162-4070-87d3-d5dc6684f56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the min\n",
    "torch.min(x), x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9d78c6e6-567d-4326-886b-2b938b1520ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the max\n",
    "## torch.max(x), x.max() \n",
    "## will give an error since its dtype is int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "516246d7-f67e-4093-affa-d2915da9657a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8e5a93d4-fdbf-4292-ba07-56ede11de06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "30dc9f66-ed53-490f-aa35-e77ec5ee46b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1195, 0.4696, 0.7130, 0.4108, 0.3722],\n",
       "         [0.2286, 0.4912, 0.8160, 0.8788, 0.0372],\n",
       "         [0.5364, 0.4690, 0.6675, 0.2379, 0.3855],\n",
       "         [0.2815, 0.0669, 0.9960, 0.6045, 0.4694]],\n",
       "\n",
       "        [[0.0237, 0.8572, 0.8429, 0.4359, 0.7402],\n",
       "         [0.3154, 0.4140, 0.5985, 0.2196, 0.0443],\n",
       "         [0.2396, 0.4045, 0.5492, 0.1609, 0.5006],\n",
       "         [0.0409, 0.1106, 0.8060, 0.1346, 0.2921]],\n",
       "\n",
       "        [[0.5316, 0.1841, 0.5472, 0.1189, 0.0035],\n",
       "         [0.0501, 0.2084, 0.8949, 0.1880, 0.8500],\n",
       "         [0.7877, 0.5864, 0.6821, 0.0059, 0.3759],\n",
       "         [0.9631, 0.2044, 0.5753, 0.9310, 0.6646]]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_dim_tensor = torch.rand(3,4,5)\n",
    "three_dim_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d448a4d6-0a12-44f5-92e5-5502c182d202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0035)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(three_dim_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49355cce-d5be-4708-9945-aa9c2e25447e",
   "metadata": {},
   "source": [
    "## Finding the positional min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "db5bf3e9-0ccc-4f76-b994-127cb5d7d5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e90de006-10b5-47a1-a9eb-4ad7ac1d2381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(9), tensor(0), tensor(90))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.argmin(), x.argmax(), x[0], x[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a002e6-6cee-48a0-994f-41af783166ce",
   "metadata": {},
   "source": [
    "## Reshaping, viewing, and stacking tensors - 2.57\n",
    "\n",
    "* Reshaping - reshapes an input tensor to a defined shape\n",
    "* View - return a view of an input tensor of certain shape but keep the same memory as the original tensor (viewing a tensor from a different perspective)\n",
    "* Stacking - combine multiple tensors on top of each other\n",
    "* Squeeze - removes all `1` dimensions from a tensor\n",
    "* Unsqueeze - add a `1` dimension to a target tensor\n",
    "* Permute - return a view of the input with dimension permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e5b3449f-ba2f-4c44-a750-3fc6482ee1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor  \n",
    "x = torch.arange(1., 10.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "00b8efeb-fb88-4e56-aad6-861ebf940037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]), 2)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshape = x.reshape(1, 9)\n",
    "x_reshape, x_reshape.shape, x_reshape.ndim\n",
    "## now the tensor become a 2d tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "79aa2ac4-4f76-49cf-b252-852fe6c4b4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]),\n",
       " 2)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshape = x.reshape(9,1)\n",
    "x_reshape, x_reshape.shape, x_reshape.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "205b026b-c343-4767-82e5-f845dbdc4e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]), torch.Size([10]))"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1., 11.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "15bc4fc7-f0ce-48d0-b0f6-0a2c39f35f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 0., 5., 9., 5.],\n",
       "         [9., 9., 9., 9., 9.]]),\n",
       " torch.Size([2, 5]),\n",
       " 2)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshape = x.reshape(2, 5) #hint: 5 * 2 = 10\n",
    "x_reshape, x_reshape.shape, x_reshape.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e38461c7-295c-40f7-a7fc-1b847db5dd3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.,  2.,  5.,  4.,  5.,  6.,  7.,  5.,  9., 10.]]),\n",
       " torch.Size([1, 10]))"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the view\n",
    "z = x.view(1, 10)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c49f138b-5cc6-419b-93f0-eceab0a9449c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 5., 5., 4., 5., 6., 7., 5., 9., 1.]]),\n",
       " tensor([5., 5., 5., 4., 5., 6., 7., 5., 9., 1.]))"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing z changes x (because a view of a tensor shares the same memory, as the original tensor\n",
    "z[0, 9] = 1 # it's like z[0][9]\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "500f8c27-a0a9-47ca-82f6-536c451d2963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 0., 5., 4., 5.],\n",
       "        [6., 0., 5., 9., 1.]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.view(2, 5) # 2 rows and 5 columns\n",
    "z[:, 1] = 0 # means that I want to set all numbers in column 1 to 0 no matter its rows\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "9e0f6a74-2f56-4357-80bb-bccdef20dabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 0., 5., 9., 5.],\n",
       "         [9., 9., 9., 9., 9.]]),\n",
       " tensor([5., 0., 5., 9., 5., 9., 9., 9., 9., 9.]))"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:, 3] = 9\n",
    "z, x # the information will be the same, but in z we see it in a different view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "013b27fc-ac45-4ea6-a812-8754b2a5eb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 0., 5., 9., 5., 9., 9., 9., 9., 9.],\n",
       "        [5., 0., 5., 9., 5., 9., 9., 9., 9., 9.],\n",
       "        [5., 0., 5., 9., 5., 9., 9., 9., 9., 9.],\n",
       "        [5., 0., 5., 9., 5., 9., 9., 9., 9., 9.]])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack tensor on top of each other (vstack dim=0)\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "d96615c2-9641-47a9-82ae-5bb7136b43ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 0., 5., 9., 5., 9., 9., 9., 9., 9.]]),\n",
       " torch.Size([1, 10]),\n",
       " tensor([5., 0., 5., 9., 5., 9., 9., 9., 9., 9.]))"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# squeezing - removes all the single dimension size 1\n",
    "x_reshape = x.reshape(1, 10)\n",
    "x_reshape, x_reshape.shape, x_reshape.squeeze() ## it changes the tensor to 1 dimension - x_reshape.size = [1, 10] so it removes all the one dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "b1d26124-7fce-4005-9b30-7f3d1a5f7502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshape.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "1181211f-ad42-4b3e-a61b-a7facc173778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5., 0., 5., 9., 5., 9., 9., 9., 9., 9.]])\n",
      "Previous shape: torch.Size([1, 10])\n",
      "\n",
      "New tensor: tensor([5., 0., 5., 9., 5., 9., 9., 9., 9., 9.])\n",
      "New shape: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# torch.squeeze(input, dim=None) - removes all single dimension from a target tensor\n",
    "print(f'Previous tensor: {x_reshape}')\n",
    "print(f'Previous shape: {x_reshape.shape}')\n",
    "\n",
    "# Remove extra dimension from x_reshape\n",
    "x_squeezed = x_reshape.squeeze()\n",
    "print(f'\\nNew tensor: {x_squeezed}')\n",
    "print(f'New shape: {x_squeezed.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "6dbace3e-0c48-4514-97da-ec8843375158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous target tensor: tensor([5., 0., 5., 9., 5., 9., 9., 9., 9., 9.])\n",
      "Previous target shape: torch.Size([10])\n",
      "\n",
      "New target tensor: tensor([[5., 0., 5., 9., 5., 9., 9., 9., 9., 9.]])\n",
      "New target shape: torch.Size([1, 10])\n",
      "\n",
      "New target tensor: tensor([[5.],\n",
      "        [0.],\n",
      "        [5.],\n",
      "        [9.],\n",
      "        [5.],\n",
      "        [9.],\n",
      "        [9.],\n",
      "        [9.],\n",
      "        [9.],\n",
      "        [9.]])\n",
      "New target shape: torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueeze(input, dim) - add a single dimension to a target tensor at a specific dim (dimension)\n",
    "print(f'Previous target tensor: {x_squeezed}')\n",
    "print(f'Previous target shape: {x_squeezed.shape}')\n",
    "\n",
    "# Add an extra dimenstion with unsqueeze at a dimension 0\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f'\\nNew target tensor: {x_unsqueezed}')\n",
    "print(f'New target shape: {x_unsqueezed.shape}')\n",
    "\n",
    "# Add an extra dimenstion with unsqueeze at a dimension 1\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=1)\n",
    "print(f'\\nNew target tensor: {x_unsqueezed}')\n",
    "print(f'New target shape: {x_unsqueezed.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "035dfb21-2361-49c4-89fd-da8bb5cea6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([244, 244, 3])\n",
      "New shape: torch.Size([3, 244, 244])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute(input, dims) - rearranges the dimensions of a target tensor in a specified order\n",
    "x_original = torch.rand(size=(244, 244, 3)) # [height, width, color_channels(rgb)]\n",
    "\n",
    "# permute the original tensor to  rearrange the axis (or dim) order \n",
    "x_permuted = x_original.permute(2, 0, 1) # [color_channels, height, width] \n",
    "\n",
    "print(f'Previous shape: {x_original.shape}')\n",
    "print(f'New shape: {x_permuted.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "a0770789-64ca-412f-b527-cff4c3bf3a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.permute Returns a view of the original tensor input with its dimensions permuted.\n",
    "## it changes the original tensor when changing the permuted tensor \n",
    "\n",
    "x_original[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "ce21c7bb-b25e-4f7b-bbfc-9e7ddd64a88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.), tensor(2.))"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_permuted[0,0,0] = 2.\n",
    "x_original[0,0,0], x_permuted[0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9b52e1-5cfc-4304-a5cf-98634127d482",
   "metadata": {},
   "source": [
    "## Indexing (selecting data from tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "ff3bbe64-ec0d-4cc4-b8ef-edfee384c690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # create a tensor with 3 dimensions\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "d229e76e-2cca-4ca7-8283-a457340a1383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index on the first dimension (dim=0)\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "0b59a6b7-607b-4f91-a426-067b306cff85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index on the second dimension (dim=1)\n",
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "014ba424-310a-4f6a-befe-17d495bca25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indec on the third dimension (dim=2)\n",
    "x[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "7242ef49-c8ef-44a7-8921-96803ac4d07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can use \":\" to select \"all\" of a target dimension\n",
    "x[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "09841993-7a23-4c23-9c05-6d8b70b73fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values 1st and 2nd dimension but only index 1 of 3rd dimension\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "65241aa2-ac3c-4a46-b92b-bae948f8b584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of the 1st dimension (dim=0) but only the 1 index value of 1st and 2nd dimension\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "82447c58-4678-43f7-92dd-c73c8db0ea99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index 0 of 1st dimension and 2nd dimension and all values of 3rd dimension\n",
    "x[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "16646d81-dda9-4514-b919-0ea53fb7dfa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index on x to return 9 \n",
    "x[0,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "4b24908a-48b1-48d0-9e08-995f8a83f242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index on x to return 3, 6, 9\n",
    "x[0, :, 2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
